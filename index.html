<!doctype html>
<html lang="en" class="no-js">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,900' rel='stylesheet' type='text/css'>

	<link rel="stylesheet" href="css/reset.css"> <!-- CSS reset -->
	<link rel="stylesheet" href="css/style.css"> <!-- Resource style -->
	<script src="js/modernizr.js"></script> <!-- Modernizr -->
</head>
<body>
	<title>UX 2: A Focus on Micro-interactions</title>
	<main>
		<div class="cd-image-block">
			<ul class="cd-images-list">
				<li class="is-selected" id="01_first">
					<a href="#0">
						<h2>Concept </h2>
					</a>
				</li>

				<li id="02_ideation">
					<a href="#0">
						<h2>Initial Ideation</h2>
					</a>
				</li>

				<li id="03_concept">
					<a href="#0">
						<h2>Concept Development</h2>
					</a>
				</li>

				<li id="04_prototyping">
					<a href="#0">
						<h2>Paper Prototyping & <br> User Testing</h2>
					</a>
				</li>
                
                <li id="05_wireframing">
					<a href="#0">
						<h2>Wireframing:</h2>
					</a>
				</li>
                
                <li id="06_motion">
					<a href="#0">
						<h2>Motion Study & <br> Higher Fidelity Prototype</h2>
					</a>
				</li>
                
                <li id="07_conclusion">
					<a href="#0">
						<h2>Conclusion</h2>
					</a>
				</li>
			</ul> <!-- .cd-images-list -->
		</div> <!-- .cd-image-block -->

		<div class="cd-content-block">
			<ul>
				<li class="is-selected">
					<div>
						<h2>A multifunction car key for a multifunctional car</h2>
						
						<p>
							It seems pretty clear that some component of almost everything man made, will be connected to the internet. Cars are included in those man-made objects and like many other objects today, they are getting 'smarter' each year. By 'smarter' I specifically mean that they are equipped with increasing functionality. Cars are connected to the internet, producing their own wifi, and even running their own applications. 
						</p>
						
						<p>
							However, right now the car key remains untapped. Even the keys of some of the most highly regarded 'smartest' cars of today, like a Tesla Model S, offer the same range of functionality as a 2004 Honda Accord. The current version of the basic electronic battery-powered car key has but a few functions: unlocking a vehicle remotely, locking a vehicle remotely, setting a vehicle into 'panic' mode, and possibly opening a trunk.
						</p>
						
						<p>
							But what if you were to take the car key and tap into the multifunctional modes of the car using a smart phone app? By letting go of a purely physical form, a better car key could better communicate with the smarter cars of today. But what would it look like? What would it feel like? What type of micro-interactions would it have? How would it be useful to the user?     
						</p>
                        
                        <h2>The goal</h2>
                        
                        <p>
                            My goal is to explore these questions and arrive a possible solution using a microinteraction. Hopefully that microinteraction will be unique enought to be a 'branded' and signiture. 
                        </p>
					</div> 
				</li>

				<li>
					<div>
						<h2>Microinteraction Breakdown</h2>
                        
                        <p>
							Before I began thinking about the project too deeply, I picked up Dan Saffer's, <i>Designing Microinteractions</i>. I only skimmed the book, but it was incredibly helpful. One of the key points was a fantastic explanation about the anatomy of a microinteraction. Microinteractions are broken down into four simple components: 
                        </p>
                        <ul>
                            <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/02_structure_diagram_big.png">
                        </ul>
                        <p>
                            Just having a simple vocabulary of the microinteraction helped me approach the task of designing a unique or signature microinteraction. 
						</p>
						
                        <h2>Batman and the Batmobile</h2>
                        
						<p>
							I began to think about the various triggers there are to start a car. The average person is pretty limited to one main interaction when it comes to the ignition of a vehicle; put the key in the ignition and turn to start the vehicle. However, there is one person who has many ways to start a vehicle. 
						</p>
						
						<h5>Cue the Batman</h5>
                        
                         <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/02_batman_siri.jpg" id="batman_siri">
                        
                        <p>
                            What were all of the different ways Batman could interact with his gadgets to start the Batmobile remotely? In the comics and movies, Batman could start the Batmobile from his wrist microphone (much like an apple watch), simply by being a certain proximity, it could start from a timer, or it could he could simple push a button to start the car.
                        </p>
                       
                        <p>
                            These initial thoughts and questions inspired the initial triggers of the microinteraction between the user's car and the user's mobile phone application. While the microinteractions could be built out for any of those triggers, I decided to focus on the one that required 'pushing a button' to start because it was the most adaptable to the mobile platform.
                        </p>
                        
                         <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/02_batman_triggers.jpg">
					</div> 
				</li>

				<li>
					<div>
						<h2>Initial Hunch</h2>
						
                        <p>
                            Soon after settling on the general type of trigger to pursue, I began to wonder about how to make it stand out as a 'signature' microinteraction. Wandering into the territory of metaphor, I really wanted to use the motions of a key into an ignition. This was represented in three main motions: the insertion, the turn, and the release. I was pretty driven to integrate those motions into the interaction of the app to create a 'signature' microinteraction.  
                        </p>
                        
                        <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/03_hunch_interaction.jpg" >
						
                        
                        <h2>Sketching out the Microinteraction</h2>
						
                        <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/03_hunch_sketch_01.jpg" id="hunch_sketch">
                        
                        <p>
							My early sketch was a simple skeleton that aimed to describe the main keyframes of the path that a user's finger would take to turn on the car. The three main elements of the interaction attempt to mimic the ignition of the car, insert, rotate, and release. However, some of my later sketches below explored the 'key' metaphor more thouroghly as the microinteraction was beginning to be organized into feedback and rules. 
						</p>
                        
                        <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/02_batman_loops.jpg">

                        <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/03_detail_sketches.jpg">
                        
                        <p>
							My imagination was running at this point, and other tasks, tasks that were beyond the scope of just turning on the vehicle started to emerge. I thought that it would be interesting to modify the 'key' swiping interaction to add functionality to the app.
						</p>
                        
                        <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/03_detail_sketches_advanced.jpg">

					</div> 
				</li>

				<li>
					<div>
						<h2>Building the Paper Prototype</h2>
						
						<p>
							The initial gestures I thought were so important to the application were difficult to build into a prototype using just paper materials. Swiping, dragging, and sliding were crucial actions that a user had to take to finish the. It was challenging to build something with paper that provides the neccessary feedback to the user during a test with a paper prototype.
						</p>
                        
                        <p>
							However, I found inspirations in the my classmate's paper prototypes, and eventually settled on building a very intricate prototype. Below is an example of the initial paper prototype that I built with some tasks to show how the interactions would work.
						</p>

                        <iframe width="100%" height="315" src="https://www.youtube.com/embed/xvms_DCXygc" frameborder="0" allowfullscreen></iframe>
                        
                        <h2>Testing Users</h2>
						<p>
							There were only a handful of users I tested with, but it was very worthwhile. I tried to concentrate on a few key insights during my tests. Firstly, what kind of vocabulary user called the elements on the screen. Most importantly, I wanted to see wether or not the main microinteraction was intuitive and smooth.  What I found definitely surprised me.
						</p>

                        <iframe width="100%" height="315" src="https://www.youtube.com/embed/kkNFwUP-w-Q" frameborder="0" allowfullscreen></iframe>
                        
                        <h2>Initial Feedback &apm; Key Insights</h2>
						
						<h5> Turning on the car was super difficult </h5>
						<p>
							The 'key' metaphor, which was the core 'signature' trigger for the microinteraction, turned simplest activities into an arduous task for users. I did anticipate that users would get stuck so I created small 'helper' labels that would 'appear' in the paper prototype if a user was taking too long to complete a task.
                            
                            Granted that providing good feedback for a swiping motion in a paper prototype is a little tricky, even with helper interstitial screens the interaction seemed clunky and many things were missed.
                        </p>
                        
                        <h5> What users actually did to start the car </h5>
						<p>
							Watching users fail miserably to turn on the car through using the key swiping motion, did provide some extremely useful insight. Most users, went to touch the center of the key handle, where the car icon is, immediately. They expected to press a button to start the car. This was huge, albeit disappointing insight.
                        </p>
                        
                        
						<h5> Swiveling the 'key' was overlooked </h5>
						<p>
							I really thought I was so clever by using the 'key' as a trigger for multiple microinteractions. I had built the prototype such that a user could tap, hold, and 'swivel' the key within a 30 degree range of motion to unlock and/or lock the vehicle. To my dismay, many users completely overlooked this feature. Although some user found easier once I placed the 'helper' alert, the swivel was overall not very intuitive.
                        </p>
                        
                        <h5> The placement of the car 'applettes' was confusing </h5>
						<p>
							The placement was generally out of reach for users who are holding a phone with one hand.
                        </p>
                        
					</div> 
				</li>
                
                <li>
					<div>
						<h2>General Revisions</h2>
                        
                        <p>
                            Overall, the feedback I received from tests was very helpful and pushed my designs into a better form of the app. The strict 'key' metaphor was abandoned, which simplified and removed a lot ambiguity from basic tasks. The locking and unlocking action, for example, was moved from the key into its own section. Although I have yet to build these new wireframes into a new prototype and test it with users, I feel like the new screens would greatly reduce the friction of the microinteraction while still keeping some of its uniqueness.
                        </p>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/wireframing_iteraction_01.jpg">
                        
                        
                        <h2>Redesigning the Wireframes</h2>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_main_screen.jpg" id="revision_wireframe">
                        
                        <div class="redesign_points">
                            <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_bullet_point_03.png" class="bullet_icon" id="blue">
                            <h5>Starting the Car</h5>
                            <p>
                               The 'key' was redesigned so that the initial trigger for starting the car was much more button-like in appearance. Also, the 'swipe' motion was replaced by a tap-and-hold. 
                            </p>
                        </div>
                        <div class="redesign_points">
                            <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_bullet_point_02.png" class="bullet_icon" id="yellow">
                            <h5>Unlocking the Car</h5>
                            <p>
                                Unlocking the car was unhinged from the 'key' trigger. Instead, it is a actionable area that includes functional labels for clarity. I'm worried that it would be redundant to use two tap-and-holds on the same screen, but this is something that is worth validating through further user-testing.
                            </p>
                        </div>
                        <div class="redesign_points">
                            <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_bullet_point_01.png" class="bullet_icon" id="red">
                            <h5>Quickstarting the car with 'apps'</h5>
                            <p>
                                There are still 'advanced' microinteractions from earlier conceptual ideas that remain in the wireframe. One of those 'advanced' interactions was the use of little 'applettes' that would allow the user to start the car with basic functions engaged.
                            </p>
                        </div>
                        <div class="redesign_points">
                            <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_bullet_point_04.png" class="bullet_icon" id="touch">
                            <h5>Moving the 'applettes'</h5>
                            <p>
                                The row of applettes were moved down to the bottom of the screen for a more ergonomic placement.
                            </p>
                        </div>
					</div> 
				</li>
                
                <li>
					<div>
                        
                        <h2>Thinking about Animation</h2>
						
						<p>
                            <a href="https://www.youtube.com/watch?v=duefsFTJXzc" target="_blank"> Romain Guy and Chet Haase of Android Team at Google</a> have a developed a great way of describing motion through animation, that went on to be very helpful in describing how animation is used in the context of UI. However, one of the best resources was the <a href="https://www.google.com/design/spec/motion/material-motion.html#material-motion-how-does-material-move" target="_blank">Material Design Guideline</a>; they describe that animation can be: fast, smooth, natural, simple, or purposeful.
                        </p>
                        <p>
                            My primary goal of starting to animatte the microinteraction was purpose. I wanted the animations to simply communicate that states are being changed. Secondly, I wanted any motion to make sense in the context of the app.
                        </p>
                        
                        <h2>Starting the Car: A Motion Study</h2>
						
                        <h5>Overview</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_motion_study_start.jpg">
                        
						<h5>Rest State</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_01_rest.png" class="motion_screen">
                        
                        <h5>Pressed State</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_02_pressed.png" class="motion_screen">
                        
                        <h5>Released State</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_03_release.png" class="motion_screen">
                        
                        <h5>Active State</h5>
                        <p>Active Example 1</p>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_04_active.png" class="motion_screen">
                        <p>Active Example 2</p>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_05_active.png" class="motion_screen">
                        
                        <h5>Complete State</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_06_complete.png" class="motion_screen">
					</div> 
				</li>
                
                <li>
					<div>
                        <h2>Moving Forward</h2>
						
                        <p>
							I feel like this is great start to the project, but there is a lot left to be done. If I can continue the project, here are a list of some things that could worked on:
                        </p>
                        
                        <h5>More User Testing</h5>

						<p>
							Going through another iteration of gathering feedback user testing, design, and prototyping would be crucial to continuing the project. I think also placing the users in a scenario where they would actually use the app, a parking lot for example, would be extremely interesting.
                        </p>
                        
                        <h5>Refining feedback loops</h5>
                        
                        <p>
							I also believe there's a lot more thought that could be refined is within the loop portion of this micro interaction. Beyond the broader feedback loop between the car and the user's smartphone application, how could smaller loops be used within the microinteraction to enhance user behavior? Is it a loop that learns, and builds frequently used presets into the 
                            
                        </p>
                        
                        <h5>Thinking about sound and haptic feedback</h5>
                        
                        <p>
							The feedback you get from starting a car, locking a car, or even turning on the air conditioning in a car uses both sound and motion. Neglecting to include audio or haptic feedback would be a missed opportunity to give the user a more complete experience familiarity while also crafting new patterns for them to enjoy and discover.
                        </p>
                        
                         <h5>Animating a motion-study</h5>

						<p>
							Obviously, the work could really benefit from refining the keyframes into a nicely animated motion study, once the wireframes have been tested again and been through another iteration of design.
                        </p>
                        
						<h2>Final Thoughts</h2>
						
						<p>
							Overall, this project served as an excellent introduction to the world of microinteractions. I feel like a whole new world opened up, and even though I only caught a glimpse into it, the process of creating a custom 'signature' microinteraction was challenging and extremely rewarding. 
                            
                            It's still amazing that something so small, like a microinteraction could be so important. A interaction that could last only a few seconds could be the detail in the design that delights, confuses, or enlightens the user.
                        </p>
                        
                        
					</div> 
				</li>
                
			</ul>

			<button class="cd-close">Close</button>
		</div> <!-- .cd-content-block -->

		<ul class="block-navigation">
			<li><button class="cd-prev inactive">&larr; Prev</button></li>
			<li><button class="cd-next">Next &rarr;</button></li>
		</ul> <!-- .block-navigation -->
	</main>	<!-- .cd-main -->
	
<script src="js/jquery-2.1.4.js"></script>
<script src="js/main.js"></script> <!-- Resource jQuery -->
</body>
</html>