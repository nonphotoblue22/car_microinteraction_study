<!doctype html>
<html lang="en" class="no-js">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,900' rel='stylesheet' type='text/css'>

	<link rel="stylesheet" href="css/reset.css"> <!-- CSS reset -->
	<link rel="stylesheet" href="css/style.css"> <!-- Resource style -->
	<script src="js/modernizr.js"></script> <!-- Modernizr -->
</head>
<body>
	<title>UX 2: A Focus on Micro-interactions</title>
	<main>
		<div class="cd-image-block">
			<ul class="cd-images-list">
				<li class="is-selected" id="01_first">
					<a href="#0">
						<h2>Concept </h2>
					</a>
				</li>

				<li id="02_ideation">
					<a href="#0">
						<h2>Initial Ideation</h2>
					</a>
				</li>

				<li id="03_concept">
					<a href="#0">
						<h2>Concept Development</h2>
					</a>
				</li>

				<li id="04_prototyping">
					<a href="#0">
						<h2>Paper Prototyping & <br> User Testing</h2>
					</a>
				</li>
                
                <li id="05_wireframing">
					<a href="#0">
						<h2>Wireframing:</h2>
					</a>
				</li>
                
                <li id="06_motion">
					<a href="#0">
						<h2>Motion Study & <br> Higher Fidelity Prototype</h2>
					</a>
				</li>
                
                <li id="07_conclusion">
					<a href="#0">
						<h2>Conclusion</h2>
					</a>
				</li>
			</ul> <!-- .cd-images-list -->
		</div> <!-- .cd-image-block -->

		<div class="cd-content-block">
			<ul>
				<li class="is-selected">
					<div>
						<h2>A multifunction car key for a multifunctional car</h2>
						
						<p>
							It seems pretty clear that some component of almost everything man made, will be connected to the internet. Cars are included in those man-made objects and like many other objects today, they are getting 'smarter' each year. By 'smarter' I specifically mean that they are equiped with increasing functionality. Cars are connected to the internet, producing their own wifi, and even running their own applications. 
						</p>
						
						<p>
							However, as of right now, the car key in it's current form has limited function. Even the keys of some of the most highly regarded 'smartest' cars of today, like a Tesla Model S, offer the same range of functionality as a 2004 Honda Accord in terms of their functionality. The current version of the basic electronic battery-powered car key has but a few functions: unlocking a vehicle remotely, locking a vehicle remotely, setting a vehicle into 'panic' mode, and possibly opening a trunk.
						</p>
						
						<p>
							But what if you were to take the car key and tap into the multifunctional modes of the car via technology. By letting go of a purely physical form, a better car key could better communicate with the smarter cars of today. But what would it look like? What would it feel like? What type of micro-interactions would it have? How would it be useful to the user?
                            
						</p>
                        
                        <h2>The goal</h2>
                        
                        <p>
                            My goal is to explore these questions and arrive a possible solution using a microinteraction. Hopefully that microinteraction will be unique enought to be a 'branded' and signiture. 
                        </p>
					</div> 
				</li>

				<li>
					<div>
						<h2>Microinteraction Breakdown</h2>
                        
                        <p>
							Before I began thinking about the project too deeply, I picked up Dan Saffer's, <i>Designing Microinteractions</i>. I just skimmed the book, but it was incredibly helpful in guiding my thoughts about microinteractions. He breaks the  of the anatomy of a microinteraction into four simple components: 
                        </p>
                        <ul>
                            <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/02_structure_diagram_big.png">
                        </ul>
                        <p>
                            Just having a simple vocabulary of the microinteraction helped me approach the task of desiging a unique or signature microinteraction. 
						</p>
						
                        <h2>Batman and the Batmobile</h2>
                        
						<p>
							With my better-informed vocabulary about microinteractions, I began to think about the various triggers there are to start a car. The average person is pretty limited to one main interaction when it comes to the ignition of a vehicle; put the key in the ignition and turn to start the vehicle. However, there is one person who has many ways to start a vehicle. 
						</p>
						
						<h5>Cue the Batman</h5>
                        
                         <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/02_batman_siri.jpg" id="batman_siri">
                        
                        <p>
                            I began thinking about the different ways Batman could interact with his gadgets to start the Batmobile remotely. In the comics and movies, Batman could start the Batmobile from his wrist microphone (much like an apple watch), simply by being a certain proximity, it could start from a timer, or it could he could simple push a button to start the car.
                        </p>
                       
                        <p>
                            These initial thoughts inspired the initial triggers of the microinteraction between the user's car and the user's mobile phone application. While the microinteractions could be built out for any of those triggers, I decided to focus on the one that required 'pushing a button' to start because it was the most adaptable to the mobile platform.
                        </p>
                        
                         <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/02_batman_triggers.jpg">
					</div> 
				</li>

				<li>
					<div>
						<h2>Initial Hunch</h2>
						
                        <p>
                            Soon after settling on the general type of trigger to persue for the microinteraction, I began thinking of ways to make it a 'signature' microinteraction. I began to wander into the territory of metaphor, and really wanted to use the motions of a key into an ignition. This was represented in three main motions: the insertion, the turn, and the release. I was pretty driven to integrate those motions into the interaction of the app to create a 'signature' microinteraction.  
                        </p>
                        
                        <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/03_hunch_interaction.jpg" >
						
                        
                        <h2>Sketching out the Microinteraction</h2>
						
                        <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/03_hunch_sketch_01.jpg" id="hunch_sketch">
                        
                        <p>
							My early sketch just traced the main keyframes of the path that a user's finger would take to turn on the car. The three main points mimic the ignition of the car, insert, rotate, and release. While the heart of the sketch tries to keep that The main difference being that the users motion would be flattened to a 2-D surface and therefore swiping would have to substitute.
						</p>
                        
                        <p>
							Some of my later sketches below explored the 'key' metaphor more thouroghly. I began to break down the keyframes in terms of basic feedback and rules. 
						</p>
                        

                        <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/03_detail_sketches.jpg">
                        
                        <p>
							I even began to move beyond and sketching other tasks that were beyond the scope of just turning on the vehicle with the app. Some other ideas on how I could couple this pattern with using 
						</p>
                        
                        <img src="https://nonphotoblue22.github.io/car_microinteraction_study/img/03_detail_sketches_advanced.jpg">

					</div> 
				</li>

				<li>
					<div>
						<h2>Building the Paper Prototype</h2>
						
						<p>
							I had diffuculty on how to build a paper prototype because my initial gestures I thought were so important to the application were dificult to build into a prototype using just paper materials. Swiping, dragging, and sliding were crutial actions that a user had to take to finish the. I struggled thinking of how do you provide the neccessary feedback to the user during a test with a paper prototype?
						</p>
                        
                        <p>
							I found inspirations in the other student's designs of the prototypes, and eventually settled on a rather intricate prototype. Below is an example of the initial paper prototype that I built with some tasks to show how the interactions would work.
						</p>

                        <iframe width="100%" height="315" src="https://www.youtube.com/embed/xvms_DCXygc" frameborder="0" allowfullscreen></iframe>
                        
                        <h2>Testing Users</h2>
						<p>
							While there were only a handful of users I tested with. With my testing I tried to concetrate on the what kind of vocabulary user called the elements on the screen and wether or not the main microinteraction went smoothly.  What I found definitely surprised me. v
						</p>

                        <iframe width="100%" height="315" src="https://www.youtube.com/embed/kkNFwUP-w-Q" frameborder="0" allowfullscreen></iframe>
                        
                        <h2>Initial Feedback & Key Insights</h2>
						
						<h5> Turning on the car was super difficult </h5>
						<p>
							The key metaphore, which was core 'signature' trigger of the microinteraction, turned simplest activity into an arduous task for users. I did anticipate that users would get stuck so I created small 'helper' labels that would 'appear' on the prototype if a user was taking too long.
                            
                            Granted that providing good feedback for a swiping motion in a paper prototype is a little tricky, even with helpers the interaction seemed clunky and was mostly overlooked.
                        </p>
                        
                        <h5> What users actually did to start the car </h5>
						<p>
							Watching users fail miserably to turn on the car through using the key swiping motion, did provide some extremely useful insight. Most users, went straght on the center of the key handle, where the car icon is, and tapped gently. They expected to press a button to start the car. This was huge, albeit dissapointing.
                        </p>
                        
                        
						<h5> Swiveling the 'key' was overlooked </h5>
						<p>
							I really thought I was so clever by using the 'key' as a trigger for multiple microinteractions. I had built the prototype such that a user could tap, hold, and 'swivel' the key within a 30 degree range of motion to unlock or lock the vehicle. 
                        </p>
                        
                        <p>
							To my dismay, many users completely overlooked. 
                        </p>
                        
                        <p>
							Unfortunately, no one understood that the key could be 
                        </p>
                        
                        <h5> The placement of the car 'applettes' was confusing </h5>
						<p>
							I really thought I was being so clever by using the 'key' as a trigger for multiple microinteractions. I had built the prototype such that a user could tap, hold, and 'swivel' the key within a 30 degree range of motion to unlock or lock the vehicle. 
                        </p>
                        
					</div> 
				</li>
                
                <li>
					<div>
						<h2>General Revisions</h2>
                        
                        <p>
                            Overall, the feedback I recieved from tests was very helpful and pushed my designs into a better form of the app. The redesigns abandoned most of the rigidity of the 'key' metaphor. The microinteractions were also simplified and many were subtracted out from ambiguity. The locking and unlocking action, for example, was removed from the key completely. Although I have yet to build these new wireframes into a new prototype and test it with users, I feel like the new screens would greatly reduce the friction of the microinteraction while still keeping some of its uniqueness.
                        </p>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/wireframing_iteraction_01.jpg">
                        
                        
                        <h2>Redesigning the Wireframes</h2>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_main_screen.jpg" id="revision_wireframe">
                        
                        <div class="redesign_points">
                            <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_bullet_point_03.png" class="bullet_icon" id="blue">
                            <h5>Starting the Car</h5>
                            <p>
                               The 'key' was redesigned so that the initial trigger for starting the car was much more button-like in appearance. Also, the 'swipe' motion was replaced by a tap-and-hold. 
                            </p>
                        </div>
                        <div class="redesign_points">
                            <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_bullet_point_02.png" class="bullet_icon" id="yellow">
                            <h5>Unlocking the Car</h5>
                            <p>
                                Unlocking the car was unhinged from the 'key' trigger. Instead, it is a actionable area that includes functional labels for clarity. I'm worried that it would be redundant to use two tap-and-holds on the same screen, but this is something that is worth validating through further user-testing.
                            </p>
                        </div>
                        <div class="redesign_points">
                            <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_bullet_point_01.png" class="bullet_icon" id="red">
                            <h5>Quickstarting the car with 'apps'</h5>
                            <p>
                                There are still 'advanced' microinteractions from earlier conceptual ideas that remain in the wireframe. One of those 'advanced' interactions was the use of little 'applettes' that would allow the user to start the car with basic functions engaged.
                            </p>
                        </div>
                        <div class="redesign_points">
                            <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/05_revision_bullet_point_04.png" class="bullet_icon" id="touch">
                            <h5>Moving the 'applettes'</h5>
                            <p>
                                The row of applettes were moved down to the bottom of the screen for a more ergonomic placement.
                            </p>
                        </div>
					</div> 
				</li>
                
                <li>
					<div>
                        
                        <h2>Thinking about Animation</h2>
						
						<p>
                            <a href="https://www.youtube.com/watch?v=duefsFTJXzc" target="_blank"> Romain Guy and Chet Haase of Android Team at Google</a> have a developed a great way of describing motion through animation, that went on to be very helpful in describing how animation is used in the context of UI. However, one of the best resources was the <a href="https://www.google.com/design/spec/motion/material-motion.html#material-motion-how-does-material-move" target="_blank">Material Design Guideline</a>; they describe that animation can be: fast, smooth, natural, simple, or purposeful.
                        </p>
                        <p>
                            My primary goal of animating the microinteraction was to make it purposeful. The animation had to communicate to the user critical information. Specifically, in terms of turning the car on, it would help if the animation  needed to know kthat when states changed from, unactive, to pressed, to active the animation should be obvious to the user. 
                        </p>
                        
                        <h2>Starting the Car: A Motion Study</h2>
						
                        <h5>Overview</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_motion_study_start.jpg" class="motion_screen">
                        
						<h5>Rest State</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_01_rest.png" class="motion_screen">
                        
                        <h5>Pressed State</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_02_pressed.png" class="motion_screen">
                        
                        <h5>Released State</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_03_release.png" class="motion_screen">
                        
                        <h5>Active State</h5>
                        <p>Active Example 1</p>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_04_active.png" class="motion_screen">
                        <p>Active Example 2</p>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_05_active.png" class="motion_screen">
                        
                        <h5>Complete State</h5>
                        <img src="http://nonphotoblue22.github.io/car_microinteraction_study/img/06_key_start_06_complete.png" class="motion_screen">
					</div> 
				</li>
                
                <li>
					<div>
                        <h2>Moving Forward</h2>
						
                        <p>
							I feel like this was a great start, but there is a lot left to be done. If this project continues, here are a list of some things that could be improved:
                        </p>
                        
                        <h5>More User Testing</h5>

						<p>
							Going through another iteration of gathering feedback user testing, design, and prototyping would be crucial to continuing the project. I think also placing the users in a scenario where they would actually use the app, a parking lot for example, would be extremely interesting.
                        </p>
                        
                        <h5>Refining feedback loops</h5>
                        
                        <p>
							I also believe there's a lot more thought that could be refined is within the loop portion of this micro interaction. Beyond the broader feedback loop between the car and the user's smartphone application, how could smaller loops be used within the microinteraction to enhance user behavior? Is it a loop that learns, and builds frequently used presets into the 
                            
                        </p>
                        
                        <h5>Thinking about sound and haptic feedback</h5>
                        
                        <p>
							The feedback you get from starting a car, locking a car, or even turning on the air conditioning in a car uses both sound and motion. Neglecting to include audio or haptic feedback would be a missed opportunity to give the user a more complete experience familiarity while also crafting new patterns for them to enjoy and discover.
                        </p>
                        
                         <h5>Animating a motion-study</h5>

						<p>
							Obvisously, the work could really benefit from refining the keyframes into a nicely animated motion study, once the wireframes have been tested again and been through another iteration of design.
                        </p>
                        
						<h2>Final Thoughts</h2>
						
						<p>
							Overall, this project served as an excellent introduction to the world of microinteractions. I feel like a whole new world opened up, and even though I only caught a glimpse into it, the process of creating a custom 'signature' microinteraction was challenging and extremely rewarding. 
                            
                            It's still amazing that something so small, like a microinteraction could be so important. A interaction that could last only a few seconds could be the detail in the design that delights, confuses, or enlightens the user.
                        </p>
                        
                        
					</div> 
				</li>
                
			</ul>

			<button class="cd-close">Close</button>
		</div> <!-- .cd-content-block -->

		<ul class="block-navigation">
			<li><button class="cd-prev inactive">&larr; Prev</button></li>
			<li><button class="cd-next">Next &rarr;</button></li>
		</ul> <!-- .block-navigation -->
	</main>	<!-- .cd-main -->
	
<script src="js/jquery-2.1.4.js"></script>
<script src="js/main.js"></script> <!-- Resource jQuery -->
</body>
</html>